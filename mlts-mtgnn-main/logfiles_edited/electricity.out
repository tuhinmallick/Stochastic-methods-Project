The recpetive field size is 187
Number of model parameters is 362385
begin training
iter:  0 | loss: 3009.069
iter:100 | loss: 395.995
iter:200 | loss: 499.616
iter:300 | loss: 258.746
iter:400 | loss: 285.990
iter:500 | loss: 270.915
iter:600 | loss: 166.379
iter:700 | loss: 259.930
iter:800 | loss: 395.061
iter:900 | loss: 211.304
iter:1000 | loss: 214.847
iter:1100 | loss: 190.492
iter:1200 | loss: 189.115
iter:1300 | loss: 214.707
iter:1400 | loss: 174.886
iter:1500 | loss: 272.445
iter:1600 | loss: 175.171
iter:1700 | loss: 285.743
iter:1800 | loss: 209.306
iter:1900 | loss: 177.439
iter:2000 | loss: 230.976
iter:2100 | loss: 212.536
iter:2200 | loss: 269.455
iter:2300 | loss: 208.188
iter:2400 | loss: 202.274
iter:2500 | loss: 210.474
iter:2600 | loss: 169.953
iter:2700 | loss: 202.316
iter:2800 | loss: 174.366
iter:2900 | loss: 180.163
iter:3000 | loss: 256.948
iter:3100 | loss: 137.436
iter:3200 | loss: 198.116
iter:3300 | loss: 200.387
iter:3400 | loss: 123.519
iter:3500 | loss: 151.040
iter:3600 | loss: 138.540
iter:3700 | loss: 174.135
iter:3800 | loss: 162.396
iter:3900 | loss: 165.842
| end of epoch   1 | time: 856.97s | train_loss 241.2323 | valid rse 0.0606 | valid rae 0.0447 | valid corr  0.9185
iter:  0 | loss: 231.293
iter:100 | loss: 173.191
iter:200 | loss: 206.071
iter:300 | loss: 93.762
iter:400 | loss: 163.475
iter:500 | loss: 164.965
iter:600 | loss: 241.499
iter:700 | loss: 147.613
iter:800 | loss: 183.957
iter:900 | loss: 131.799
iter:1000 | loss: 187.131
iter:1100 | loss: 162.216
iter:1200 | loss: 158.314
iter:1300 | loss: 175.119
iter:1400 | loss: 220.675
iter:1500 | loss: 132.228
iter:1600 | loss: 151.652
iter:1700 | loss: 278.070
iter:1800 | loss: 168.020
iter:1900 | loss: 159.222
iter:2000 | loss: 189.448
iter:2100 | loss: 178.768
iter:2200 | loss: 194.161
iter:2300 | loss: 138.661
iter:2400 | loss: 126.892
iter:2500 | loss: 168.399
iter:2600 | loss: 139.309
iter:2700 | loss: 254.222
iter:2800 | loss: 146.863
iter:2900 | loss: 212.035
iter:3000 | loss: 170.724
iter:3100 | loss: 183.186
iter:3200 | loss: 163.191
iter:3300 | loss: 172.881
iter:3400 | loss: 142.432
iter:3500 | loss: 134.525
iter:3600 | loss: 180.551
iter:3700 | loss: 301.368
iter:3800 | loss: 147.081
iter:3900 | loss: 166.841
| end of epoch   2 | time: 857.16s | train_loss 182.3065 | valid rse 0.0606 | valid rae 0.0417 | valid corr  0.9251
iter:  0 | loss: 172.567
iter:100 | loss: 171.357
iter:200 | loss: 156.679
iter:300 | loss: 149.943
iter:400 | loss: 135.808
iter:500 | loss: 177.703
iter:600 | loss: 155.787
iter:700 | loss: 220.771
iter:800 | loss: 161.023
iter:900 | loss: 218.897
iter:1000 | loss: 209.790
iter:1100 | loss: 214.407
iter:1200 | loss: 152.309
iter:1300 | loss: 173.107
iter:1400 | loss: 135.523
iter:1500 | loss: 158.328
iter:1600 | loss: 201.355
iter:1700 | loss: 128.953
iter:1800 | loss: 132.580
iter:1900 | loss: 126.604
iter:2000 | loss: 220.603
iter:2100 | loss: 170.410
iter:2200 | loss: 191.772
iter:2300 | loss: 152.451
iter:2400 | loss: 178.931
iter:2500 | loss: 207.657
iter:2600 | loss: 134.268
iter:2700 | loss: 118.742
iter:2800 | loss: 201.515
iter:2900 | loss: 131.956
iter:3000 | loss: 231.476
iter:3100 | loss: 151.414
iter:3200 | loss: 246.138
iter:3300 | loss: 210.713
iter:3400 | loss: 138.841
iter:3500 | loss: 134.129
iter:3600 | loss: 134.468
iter:3700 | loss: 117.100
iter:3800 | loss: 221.879
iter:3900 | loss: 211.750
| end of epoch   3 | time: 858.88s | train_loss 171.7597 | valid rse 0.0547 | valid rae 0.0387 | valid corr  0.9296
iter:  0 | loss: 185.766
iter:100 | loss: 119.354
iter:200 | loss: 164.900
iter:300 | loss: 129.684
iter:400 | loss: 189.402
iter:500 | loss: 255.022
iter:600 | loss: 165.801
iter:700 | loss: 166.405
iter:800 | loss: 155.227
iter:900 | loss: 142.013
iter:1000 | loss: 188.166
iter:1100 | loss: 245.310
iter:1200 | loss: 175.491
iter:1300 | loss: 209.099
iter:1400 | loss: 264.670
iter:1500 | loss: 152.118
iter:1600 | loss: 172.650
iter:1700 | loss: 153.887
iter:1800 | loss: 165.970
iter:1900 | loss: 124.178
iter:2000 | loss: 134.641
iter:2100 | loss: 154.639
iter:2200 | loss: 179.503
iter:2300 | loss: 211.308
iter:2400 | loss: 146.271
iter:2500 | loss: 115.970
iter:2600 | loss: 176.434
iter:2700 | loss: 135.849
iter:2800 | loss: 116.683
iter:2900 | loss: 146.868
iter:3000 | loss: 139.019
iter:3100 | loss: 150.025
iter:3200 | loss: 130.207
iter:3300 | loss: 135.098
iter:3400 | loss: 136.976
iter:3500 | loss: 111.072
iter:3600 | loss: 141.219
iter:3700 | loss: 112.746
iter:3800 | loss: 144.640
iter:3900 | loss: 150.153
| end of epoch   4 | time: 858.93s | train_loss 166.0643 | valid rse 0.0538 | valid rae 0.0386 | valid corr  0.9293
iter:  0 | loss: 242.129
iter:100 | loss: 273.216
iter:200 | loss: 169.206
iter:300 | loss: 137.564
iter:400 | loss: 160.188
iter:500 | loss: 181.755
iter:600 | loss: 164.760
iter:700 | loss: 228.858
iter:800 | loss: 145.724
iter:900 | loss: 163.776
iter:1000 | loss: 98.194
iter:1100 | loss: 202.905
iter:1200 | loss: 97.027
iter:1300 | loss: 180.396
iter:1400 | loss: 188.088
iter:1500 | loss: 148.134
iter:1600 | loss: 172.680
iter:1700 | loss: 147.900
iter:1800 | loss: 155.884
iter:1900 | loss: 120.376
iter:2000 | loss: 219.688
iter:2100 | loss: 149.137
iter:2200 | loss: 193.029
iter:2300 | loss: 135.728
iter:2400 | loss: 212.947
iter:2500 | loss: 119.399
iter:2600 | loss: 164.860
iter:2700 | loss: 141.435
iter:2800 | loss: 123.927
iter:2900 | loss: 156.489
iter:3000 | loss: 149.668
iter:3100 | loss: 125.788
iter:3200 | loss: 146.258
iter:3300 | loss: 115.666
iter:3400 | loss: 117.323
iter:3500 | loss: 258.556
iter:3600 | loss: 120.617
iter:3700 | loss: 219.831
iter:3800 | loss: 150.079
iter:3900 | loss: 151.467
| end of epoch   5 | time: 858.19s | train_loss 162.6623 | valid rse 0.0540 | valid rae 0.0382 | valid corr  0.9342
test rse 0.0820 | test rae 0.0461 | test corr 0.9417
iter:  0 | loss: 154.778
iter:100 | loss: 164.526
iter:200 | loss: 123.709
iter:300 | loss: 266.078
iter:400 | loss: 170.346
iter:500 | loss: 147.612
iter:600 | loss: 165.027
iter:700 | loss: 183.092
iter:800 | loss: 132.389
iter:900 | loss: 174.782
iter:1000 | loss: 167.552
iter:1100 | loss: 151.744
iter:1200 | loss: 123.638
iter:1300 | loss: 115.679
iter:1400 | loss: 117.160
iter:1500 | loss: 211.719
iter:1600 | loss: 183.883
iter:1700 | loss: 165.627
iter:1800 | loss: 94.888
iter:1900 | loss: 164.107
iter:2000 | loss: 131.705
iter:2100 | loss: 167.839
iter:2200 | loss: 177.205
iter:2300 | loss: 183.202
iter:2400 | loss: 127.048
iter:2500 | loss: 148.355
iter:2600 | loss: 149.698
iter:2700 | loss: 208.625
iter:2800 | loss: 158.848
iter:2900 | loss: 203.114
iter:3000 | loss: 227.891
iter:3100 | loss: 150.327
iter:3200 | loss: 133.208
iter:3300 | loss: 162.539
iter:3400 | loss: 183.078
iter:3500 | loss: 188.731
iter:3600 | loss: 109.245
iter:3700 | loss: 151.504
iter:3800 | loss: 127.808
iter:3900 | loss: 129.582
| end of epoch   6 | time: 858.16s | train_loss 159.8698 | valid rse 0.0529 | valid rae 0.0374 | valid corr  0.9326
iter:  0 | loss: 152.848
iter:100 | loss: 141.731
iter:200 | loss: 148.044
iter:300 | loss: 147.710
iter:400 | loss: 126.127
iter:500 | loss: 134.272
iter:600 | loss: 214.524
iter:700 | loss: 182.157
iter:800 | loss: 143.081
iter:900 | loss: 118.359
iter:1000 | loss: 113.352
iter:1100 | loss: 133.331
iter:1200 | loss: 127.183
iter:1300 | loss: 187.507
iter:1400 | loss: 164.367
iter:1500 | loss: 170.495
iter:1600 | loss: 124.540
iter:1700 | loss: 185.352
iter:1800 | loss: 137.011
iter:1900 | loss: 147.973
iter:2000 | loss: 275.728
iter:2100 | loss: 145.334
iter:2200 | loss: 128.056
iter:2300 | loss: 117.768
iter:2400 | loss: 222.329
iter:2500 | loss: 181.910
iter:2600 | loss: 136.682
iter:2700 | loss: 220.037
iter:2800 | loss: 141.409
iter:2900 | loss: 181.670
iter:3000 | loss: 173.104
iter:3100 | loss: 168.385
iter:3200 | loss: 115.729
iter:3300 | loss: 173.849
iter:3400 | loss: 177.622
iter:3500 | loss: 182.319
iter:3600 | loss: 155.182
iter:3700 | loss: 161.640
iter:3800 | loss: 200.106
iter:3900 | loss: 179.910
| end of epoch   7 | time: 859.62s | train_loss 158.0562 | valid rse 0.0548 | valid rae 0.0400 | valid corr  0.9341
iter:  0 | loss: 147.470
iter:100 | loss: 218.847
iter:200 | loss: 113.845
iter:300 | loss: 201.276
iter:400 | loss: 211.801
iter:500 | loss: 151.521
iter:600 | loss: 265.504
iter:700 | loss: 181.710
iter:800 | loss: 171.422
iter:900 | loss: 121.704
iter:1000 | loss: 181.837
iter:1100 | loss: 202.630
iter:1200 | loss: 128.334
iter:1300 | loss: 152.444
iter:1400 | loss: 203.198
iter:1500 | loss: 179.289
iter:1600 | loss: 133.116
iter:1700 | loss: 110.056
iter:1800 | loss: 92.800
iter:1900 | loss: 137.848
iter:2000 | loss: 165.418
iter:2100 | loss: 129.533
iter:2200 | loss: 122.437
iter:2300 | loss: 153.504
iter:2400 | loss: 106.006
iter:2500 | loss: 122.949
iter:2600 | loss: 125.103
iter:2700 | loss: 166.610
iter:2800 | loss: 137.376
iter:2900 | loss: 135.740
iter:3000 | loss: 108.622
iter:3100 | loss: 167.471
iter:3200 | loss: 126.842
iter:3300 | loss: 114.519
iter:3400 | loss: 244.040
iter:3500 | loss: 141.698
iter:3600 | loss: 146.400
iter:3700 | loss: 134.800
iter:3800 | loss: 189.908
iter:3900 | loss: 108.843
| end of epoch   8 | time: 859.68s | train_loss 156.7145 | valid rse 0.0543 | valid rae 0.0386 | valid corr  0.9349
iter:  0 | loss: 168.904
iter:100 | loss: 160.109
iter:200 | loss: 167.373
iter:300 | loss: 111.474
iter:400 | loss: 131.274
iter:500 | loss: 207.051
iter:600 | loss: 139.361
iter:700 | loss: 108.938
iter:800 | loss: 103.429
iter:900 | loss: 126.927
iter:1000 | loss: 151.777
iter:1100 | loss: 212.901
iter:1200 | loss: 109.844
iter:1300 | loss: 195.687
iter:1400 | loss: 176.072
iter:1500 | loss: 200.852
iter:1600 | loss: 254.097
iter:1700 | loss: 147.737
iter:1800 | loss: 215.486
iter:1900 | loss: 196.533
iter:2000 | loss: 167.079
iter:2100 | loss: 161.230
iter:2200 | loss: 210.103
iter:2300 | loss: 184.727
iter:2400 | loss: 182.924
iter:2500 | loss: 115.369
iter:2600 | loss: 139.279
iter:2700 | loss: 183.051
iter:2800 | loss: 156.195
iter:2900 | loss: 113.216
iter:3000 | loss: 272.870
iter:3100 | loss: 197.724
iter:3200 | loss: 123.834
iter:3300 | loss: 124.985
iter:3400 | loss: 223.080
iter:3500 | loss: 136.455
iter:3600 | loss: 159.975
iter:3700 | loss: 211.201
iter:3800 | loss: 165.119
iter:3900 | loss: 162.446
| end of epoch   9 | time: 858.74s | train_loss 155.7996 | valid rse 0.0522 | valid rae 0.0372 | valid corr  0.9347
iter:  0 | loss: 173.236
iter:100 | loss: 95.505
iter:200 | loss: 136.465
iter:300 | loss: 117.002
iter:400 | loss: 169.506
iter:500 | loss: 107.139
iter:600 | loss: 111.192
iter:700 | loss: 143.854
iter:800 | loss: 145.573
iter:900 | loss: 101.340
iter:1000 | loss: 138.163
iter:1100 | loss: 131.551
iter:1200 | loss: 89.292
iter:1300 | loss: 164.549
iter:1400 | loss: 212.040
iter:1500 | loss: 136.652
iter:1600 | loss: 168.702
iter:1700 | loss: 297.886
iter:1800 | loss: 110.763
iter:1900 | loss: 184.922
iter:2000 | loss: 154.625
iter:2100 | loss: 209.077
iter:2200 | loss: 153.221
iter:2300 | loss: 209.765
iter:2400 | loss: 162.888
iter:2500 | loss: 112.355
iter:2600 | loss: 202.294
iter:2700 | loss: 152.123
iter:2800 | loss: 126.429
iter:2900 | loss: 197.596
iter:3000 | loss: 192.820
iter:3100 | loss: 147.249
iter:3200 | loss: 130.919
iter:3300 | loss: 177.193
iter:3400 | loss: 198.364
iter:3500 | loss: 134.302
iter:3600 | loss: 168.738
iter:3700 | loss: 158.552
iter:3800 | loss: 149.419
iter:3900 | loss: 109.619
| end of epoch  10 | time: 858.96s | train_loss 154.6516 | valid rse 0.0515 | valid rae 0.0364 | valid corr  0.9354
test rse 0.0784 | test rae 0.0436 | test corr 0.9426
iter:  0 | loss: 140.048
iter:100 | loss: 126.539
iter:200 | loss: 280.976
iter:300 | loss: 181.714
iter:400 | loss: 136.549
iter:500 | loss: 153.219
iter:600 | loss: 141.027
iter:700 | loss: 104.765
iter:800 | loss: 128.438
iter:900 | loss: 122.917
iter:1000 | loss: 129.745
iter:1100 | loss: 144.460
iter:1200 | loss: 151.492
iter:1300 | loss: 137.347
iter:1400 | loss: 160.178
iter:1500 | loss: 123.908
iter:1600 | loss: 115.033
iter:1700 | loss: 163.275
iter:1800 | loss: 119.128
iter:1900 | loss: 218.580
iter:2000 | loss: 142.161
iter:2100 | loss: 161.714
iter:2200 | loss: 153.187
iter:2300 | loss: 171.645
iter:2400 | loss: 169.076
iter:2500 | loss: 189.540
iter:2600 | loss: 174.866
iter:2700 | loss: 134.536
iter:2800 | loss: 162.721
iter:2900 | loss: 153.502
iter:3000 | loss: 200.447
iter:3100 | loss: 116.825
iter:3200 | loss: 248.088
iter:3300 | loss: 186.668
iter:3400 | loss: 284.565
iter:3500 | loss: 117.060
iter:3600 | loss: 169.696
iter:3700 | loss: 209.700
iter:3800 | loss: 138.331
iter:3900 | loss: 219.294
| end of epoch  11 | time: 859.70s | train_loss 153.8303 | valid rse 0.0533 | valid rae 0.0370 | valid corr  0.9353
iter:  0 | loss: 146.333
iter:100 | loss: 176.449
iter:200 | loss: 116.371
iter:300 | loss: 100.381
iter:400 | loss: 160.388
iter:500 | loss: 125.065
iter:600 | loss: 160.288
iter:700 | loss: 122.869
iter:800 | loss: 150.339
iter:900 | loss: 133.446
iter:1000 | loss: 170.868
iter:1100 | loss: 137.691
iter:1200 | loss: 112.555
iter:1300 | loss: 141.969
iter:1400 | loss: 171.090
iter:1500 | loss: 128.459
iter:1600 | loss: 284.014
iter:1700 | loss: 159.471
iter:1800 | loss: 161.398
iter:1900 | loss: 161.488
iter:2000 | loss: 157.672
iter:2100 | loss: 118.148
iter:2200 | loss: 129.650
iter:2300 | loss: 158.679
iter:2400 | loss: 169.055
iter:2500 | loss: 168.353
iter:2600 | loss: 132.919
iter:2700 | loss: 164.632
iter:2800 | loss: 126.715
iter:2900 | loss: 179.242
iter:3000 | loss: 125.848
iter:3100 | loss: 138.174
iter:3200 | loss: 235.886
iter:3300 | loss: 167.015
iter:3400 | loss: 135.519
iter:3500 | loss: 130.416
iter:3600 | loss: 149.619
iter:3700 | loss: 162.330
iter:3800 | loss: 124.140
iter:3900 | loss: 201.876
| end of epoch  12 | time: 858.78s | train_loss 152.7237 | valid rse 0.0528 | valid rae 0.0369 | valid corr  0.9374
iter:  0 | loss: 113.569
iter:100 | loss: 102.084
iter:200 | loss: 153.181
iter:300 | loss: 139.038
iter:400 | loss: 169.093
iter:500 | loss: 166.242
iter:600 | loss: 171.536
iter:700 | loss: 195.434
iter:800 | loss: 159.809
iter:900 | loss: 193.030
iter:1000 | loss: 139.418
iter:1100 | loss: 132.299
iter:1200 | loss: 149.215
iter:1300 | loss: 129.560
iter:1400 | loss: 161.245
iter:1500 | loss: 150.430
iter:1600 | loss: 123.803
iter:1700 | loss: 152.823
iter:1800 | loss: 114.837
iter:1900 | loss: 139.282
iter:2000 | loss: 123.760
iter:2100 | loss: 324.664
iter:2200 | loss: 128.314
iter:2300 | loss: 99.675
iter:2400 | loss: 161.944
iter:2500 | loss: 146.598
iter:2600 | loss: 160.563
iter:2700 | loss: 147.441
iter:2800 | loss: 110.608
iter:2900 | loss: 174.900
iter:3000 | loss: 182.916
iter:3100 | loss: 172.226
iter:3200 | loss: 87.882
iter:3300 | loss: 175.745
iter:3400 | loss: 153.248
iter:3500 | loss: 171.846
iter:3600 | loss: 125.491
iter:3700 | loss: 145.605
iter:3800 | loss: 215.937
iter:3900 | loss: 172.807
| end of epoch  13 | time: 859.34s | train_loss 152.2863 | valid rse 0.0512 | valid rae 0.0364 | valid corr  0.9363
iter:  0 | loss: 127.995
iter:100 | loss: 176.064
iter:200 | loss: 171.448
iter:300 | loss: 232.257
iter:400 | loss: 215.784
iter:500 | loss: 187.684
iter:600 | loss: 146.561
iter:700 | loss: 152.715
iter:800 | loss: 165.604
iter:900 | loss: 152.449
iter:1000 | loss: 149.061
iter:1100 | loss: 289.526
iter:1200 | loss: 136.137
iter:1300 | loss: 171.884
iter:1400 | loss: 130.257
iter:1500 | loss: 182.387
iter:1600 | loss: 158.391
iter:1700 | loss: 110.979
iter:1800 | loss: 105.926
iter:1900 | loss: 240.863
iter:2000 | loss: 101.496
iter:2100 | loss: 233.227
iter:2200 | loss: 151.326
iter:2300 | loss: 159.579
iter:2400 | loss: 176.212
iter:2500 | loss: 195.393
iter:2600 | loss: 239.362
iter:2700 | loss: 148.614
iter:2800 | loss: 128.490
iter:2900 | loss: 113.059
iter:3000 | loss: 136.855
iter:3100 | loss: 200.597
iter:3200 | loss: 109.551
iter:3300 | loss: 184.257
iter:3400 | loss: 156.775
iter:3500 | loss: 155.873
iter:3600 | loss: 255.273
iter:3700 | loss: 94.899
iter:3800 | loss: 177.397
iter:3900 | loss: 150.201
| end of epoch  14 | time: 860.11s | train_loss 151.8083 | valid rse 0.0516 | valid rae 0.0365 | valid corr  0.9366
iter:  0 | loss: 151.382
iter:100 | loss: 212.207
iter:200 | loss: 125.667
iter:300 | loss: 250.186
iter:400 | loss: 140.939
iter:500 | loss: 146.268
iter:600 | loss: 146.970
iter:700 | loss: 121.282
iter:800 | loss: 253.646
iter:900 | loss: 143.587
iter:1000 | loss: 169.415
iter:1100 | loss: 166.107
iter:1200 | loss: 151.364
iter:1300 | loss: 115.895
iter:1400 | loss: 166.162
iter:1500 | loss: 207.485
iter:1600 | loss: 202.174
iter:1700 | loss: 121.167
iter:1800 | loss: 134.303
iter:1900 | loss: 186.231
iter:2000 | loss: 141.294
iter:2100 | loss: 114.006
iter:2200 | loss: 134.880
iter:2300 | loss: 98.689
iter:2400 | loss: 153.406
iter:2500 | loss: 152.109
iter:2600 | loss: 150.330
iter:2700 | loss: 136.327
iter:2800 | loss: 165.485
iter:2900 | loss: 169.660
iter:3000 | loss: 109.574
iter:3100 | loss: 156.746
iter:3200 | loss: 159.081
iter:3300 | loss: 131.533
iter:3400 | loss: 142.387
iter:3500 | loss: 151.370
iter:3600 | loss: 128.039
iter:3700 | loss: 123.522
iter:3800 | loss: 138.989
iter:3900 | loss: 144.792
| end of epoch  15 | time: 858.37s | train_loss 151.2209 | valid rse 0.0507 | valid rae 0.0362 | valid corr  0.9368
test rse 0.0765 | test rae 0.0430 | test corr 0.9433
iter:  0 | loss: 201.395
iter:100 | loss: 215.354
iter:200 | loss: 246.210
iter:300 | loss: 147.040
iter:400 | loss: 134.518
iter:500 | loss: 118.664
iter:600 | loss: 162.937
iter:700 | loss: 151.674
iter:800 | loss: 117.529
iter:900 | loss: 146.464
iter:1000 | loss: 119.270
iter:1100 | loss: 222.438
iter:1200 | loss: 163.892
iter:1300 | loss: 178.089
iter:1400 | loss: 186.728
iter:1500 | loss: 131.676
iter:1600 | loss: 141.481
iter:1700 | loss: 105.957
iter:1800 | loss: 123.463
iter:1900 | loss: 262.665
iter:2000 | loss: 162.167
iter:2100 | loss: 108.204
iter:2200 | loss: 148.287
iter:2300 | loss: 110.499
iter:2400 | loss: 121.928
iter:2500 | loss: 94.198
iter:2600 | loss: 162.001
iter:2700 | loss: 137.310
iter:2800 | loss: 196.043
iter:2900 | loss: 110.008
iter:3000 | loss: 163.554
iter:3100 | loss: 120.456
iter:3200 | loss: 117.586
iter:3300 | loss: 205.595
iter:3400 | loss: 223.770
iter:3500 | loss: 142.484
iter:3600 | loss: 174.388
iter:3700 | loss: 154.207
iter:3800 | loss: 206.521
iter:3900 | loss: 118.464
| end of epoch  16 | time: 858.65s | train_loss 150.2888 | valid rse 0.0510 | valid rae 0.0361 | valid corr  0.9366
iter:  0 | loss: 107.293
iter:100 | loss: 143.256
iter:200 | loss: 219.081
iter:300 | loss: 111.942
iter:400 | loss: 134.518
iter:500 | loss: 112.826
iter:600 | loss: 117.346
iter:700 | loss: 131.647
iter:800 | loss: 166.352
iter:900 | loss: 140.744
iter:1000 | loss: 133.646
iter:1100 | loss: 206.773
iter:1200 | loss: 262.090
iter:1300 | loss: 131.469
iter:1400 | loss: 188.340
iter:1500 | loss: 163.886
iter:1600 | loss: 173.332
iter:1700 | loss: 182.595
iter:1800 | loss: 160.797
iter:1900 | loss: 286.670
iter:2000 | loss: 128.828
iter:2100 | loss: 117.508
iter:2200 | loss: 156.665
iter:2300 | loss: 195.174
iter:2400 | loss: 135.889
iter:2500 | loss: 87.415
iter:2600 | loss: 169.606
iter:2700 | loss: 169.175
iter:2800 | loss: 301.073
iter:2900 | loss: 123.725
iter:3000 | loss: 136.549
iter:3100 | loss: 125.220
iter:3200 | loss: 138.247
iter:3300 | loss: 129.366
iter:3400 | loss: 199.780
iter:3500 | loss: 103.375
iter:3600 | loss: 110.734
iter:3700 | loss: 122.750
iter:3800 | loss: 108.052
iter:3900 | loss: 173.338
| end of epoch  17 | time: 859.86s | train_loss 149.7471 | valid rse 0.0544 | valid rae 0.0385 | valid corr  0.9384
iter:  0 | loss: 177.403
iter:100 | loss: 147.039
iter:200 | loss: 218.105
iter:300 | loss: 159.989
iter:400 | loss: 107.702
iter:500 | loss: 234.535
iter:600 | loss: 148.485
iter:700 | loss: 115.859
iter:800 | loss: 134.342
iter:900 | loss: 127.459
iter:1000 | loss: 98.592
iter:1100 | loss: 183.807
iter:1200 | loss: 120.141
iter:1300 | loss: 153.486
iter:1400 | loss: 166.168
iter:1500 | loss: 166.761
iter:1600 | loss: 133.499
iter:1700 | loss: 122.461
iter:1800 | loss: 208.537
iter:1900 | loss: 110.841
iter:2000 | loss: 130.437
iter:2100 | loss: 209.589
iter:2200 | loss: 219.083
iter:2300 | loss: 103.103
iter:2400 | loss: 128.378
iter:2500 | loss: 149.802
iter:2600 | loss: 104.350
iter:2700 | loss: 184.449
iter:2800 | loss: 168.655
iter:2900 | loss: 157.438
iter:3000 | loss: 109.535
iter:3100 | loss: 194.386
iter:3200 | loss: 177.056
iter:3300 | loss: 112.181
iter:3400 | loss: 206.870
iter:3500 | loss: 204.677
iter:3600 | loss: 148.429
iter:3700 | loss: 166.061
iter:3800 | loss: 212.923
iter:3900 | loss: 247.859
| end of epoch  18 | time: 860.23s | train_loss 149.0669 | valid rse 0.0529 | valid rae 0.0388 | valid corr  0.9372
iter:  0 | loss: 153.908
iter:100 | loss: 127.974
iter:200 | loss: 102.388
iter:300 | loss: 167.551
iter:400 | loss: 138.174
iter:500 | loss: 120.264
iter:600 | loss: 162.402
iter:700 | loss: 149.037
iter:800 | loss: 110.437
iter:900 | loss: 182.756
iter:1000 | loss: 110.329
iter:1100 | loss: 198.017
iter:1200 | loss: 146.697
iter:1300 | loss: 170.646
iter:1400 | loss: 160.923
iter:1500 | loss: 124.715
iter:1600 | loss: 155.632
iter:1700 | loss: 192.222
iter:1800 | loss: 211.294
iter:1900 | loss: 145.854
iter:2000 | loss: 145.932
iter:2100 | loss: 106.511
iter:2200 | loss: 131.698
iter:2300 | loss: 161.436
iter:2400 | loss: 141.753
iter:2500 | loss: 140.044
iter:2600 | loss: 119.086
iter:2700 | loss: 112.509
iter:2800 | loss: 140.049
iter:2900 | loss: 163.057
iter:3000 | loss: 110.141
iter:3100 | loss: 143.167
iter:3200 | loss: 153.303
iter:3300 | loss: 233.887
iter:3400 | loss: 178.850
iter:3500 | loss: 140.468
iter:3600 | loss: 151.181
iter:3700 | loss: 125.527
iter:3800 | loss: 127.639
iter:3900 | loss: 164.067
| end of epoch  19 | time: 859.55s | train_loss 148.6814 | valid rse 0.0506 | valid rae 0.0358 | valid corr  0.9385
iter:  0 | loss: 133.085
iter:100 | loss: 118.127
iter:200 | loss: 130.750
iter:300 | loss: 166.222
iter:400 | loss: 140.530
iter:500 | loss: 275.495
iter:600 | loss: 150.316
iter:700 | loss: 209.337
iter:800 | loss: 111.810
iter:900 | loss: 123.493
iter:1000 | loss: 165.506
iter:1100 | loss: 140.072
iter:1200 | loss: 151.812
iter:1300 | loss: 141.012
iter:1400 | loss: 129.952
iter:1500 | loss: 112.144
iter:1600 | loss: 164.386
iter:1700 | loss: 138.707
iter:1800 | loss: 162.004
iter:1900 | loss: 142.184
iter:2000 | loss: 117.397
iter:2100 | loss: 117.864
iter:2200 | loss: 126.998
iter:2300 | loss: 141.608
iter:2400 | loss: 152.270
iter:2500 | loss: 101.547
iter:2600 | loss: 121.985
iter:2700 | loss: 126.299
iter:2800 | loss: 122.547
iter:2900 | loss: 132.964
iter:3000 | loss: 111.310
iter:3100 | loss: 131.954
iter:3200 | loss: 117.627
iter:3300 | loss: 149.400
iter:3400 | loss: 168.643
iter:3500 | loss: 107.736
iter:3600 | loss: 167.351
iter:3700 | loss: 179.830
iter:3800 | loss: 116.136
iter:3900 | loss: 141.491
| end of epoch  20 | time: 859.79s | train_loss 148.6451 | valid rse 0.0510 | valid rae 0.0361 | valid corr  0.9388
test rse 0.0765 | test rae 0.0431 | test corr 0.9451
iter:  0 | loss: 133.422
iter:100 | loss: 149.267
iter:200 | loss: 145.519
iter:300 | loss: 251.021
iter:400 | loss: 238.800
iter:500 | loss: 124.679
iter:600 | loss: 111.967
iter:700 | loss: 94.971
iter:800 | loss: 127.085
iter:900 | loss: 84.672
iter:1000 | loss: 87.720
iter:1100 | loss: 179.106
iter:1200 | loss: 119.376
iter:1300 | loss: 108.203
iter:1400 | loss: 142.118
iter:1500 | loss: 116.822
iter:1600 | loss: 196.634
iter:1700 | loss: 126.153
iter:1800 | loss: 126.234
iter:1900 | loss: 193.117
iter:2000 | loss: 170.158
iter:2100 | loss: 199.581
iter:2200 | loss: 105.055
iter:2300 | loss: 134.097
iter:2400 | loss: 121.749
iter:2500 | loss: 129.226
iter:2600 | loss: 120.060
iter:2700 | loss: 93.375
iter:2800 | loss: 176.521
iter:2900 | loss: 168.999
iter:3000 | loss: 143.062
iter:3100 | loss: 95.677
iter:3200 | loss: 123.364
iter:3300 | loss: 111.667
iter:3400 | loss: 141.254
iter:3500 | loss: 241.645
iter:3600 | loss: 109.728
iter:3700 | loss: 144.219
iter:3800 | loss: 195.754
iter:3900 | loss: 169.032
| end of epoch  21 | time: 859.34s | train_loss 148.0090 | valid rse 0.0535 | valid rae 0.0390 | valid corr  0.9387
iter:  0 | loss: 133.486
iter:100 | loss: 170.619
iter:200 | loss: 81.549
iter:300 | loss: 199.166
iter:400 | loss: 117.394
iter:500 | loss: 137.157
iter:600 | loss: 115.346
iter:700 | loss: 129.577
iter:800 | loss: 198.752
iter:900 | loss: 114.574
iter:1000 | loss: 126.807
iter:1100 | loss: 103.388
iter:1200 | loss: 125.513
iter:1300 | loss: 121.988
iter:1400 | loss: 111.845
iter:1500 | loss: 102.373
iter:1600 | loss: 113.559
iter:1700 | loss: 131.679
iter:1800 | loss: 91.983
iter:1900 | loss: 177.486
iter:2000 | loss: 108.001
iter:2100 | loss: 121.756
iter:2200 | loss: 111.918
iter:2300 | loss: 207.471
iter:2400 | loss: 130.671
iter:2500 | loss: 204.660
iter:2600 | loss: 122.953
iter:2700 | loss: 139.658
iter:2800 | loss: 91.924
iter:2900 | loss: 199.873
iter:3000 | loss: 94.401
iter:3100 | loss: 124.216
iter:3200 | loss: 176.418
iter:3300 | loss: 141.392
iter:3400 | loss: 163.339
iter:3500 | loss: 134.193
iter:3600 | loss: 83.658
iter:3700 | loss: 132.769
iter:3800 | loss: 149.828
iter:3900 | loss: 177.870
| end of epoch  22 | time: 859.34s | train_loss 147.2614 | valid rse 0.0508 | valid rae 0.0356 | valid corr  0.9373
iter:  0 | loss: 124.515
iter:100 | loss: 170.342
iter:200 | loss: 122.800
iter:300 | loss: 114.352
iter:400 | loss: 157.715
iter:500 | loss: 135.861
iter:600 | loss: 149.721
iter:700 | loss: 207.662
iter:800 | loss: 121.922
iter:900 | loss: 104.198
iter:1000 | loss: 152.544
iter:1100 | loss: 130.193
iter:1200 | loss: 238.536
iter:1300 | loss: 100.350
iter:1400 | loss: 145.448
iter:1500 | loss: 188.900
iter:1600 | loss: 235.363
iter:1700 | loss: 190.171
iter:1800 | loss: 134.915
iter:1900 | loss: 157.509
iter:2000 | loss: 174.908
iter:2100 | loss: 119.467
iter:2200 | loss: 159.825
iter:2300 | loss: 158.309
iter:2400 | loss: 148.687
iter:2500 | loss: 192.820
iter:2600 | loss: 137.413
iter:2700 | loss: 174.044
iter:2800 | loss: 122.851
iter:2900 | loss: 116.363
iter:3000 | loss: 124.656
iter:3100 | loss: 113.576
iter:3200 | loss: 133.865
iter:3300 | loss: 160.489
iter:3400 | loss: 159.659
iter:3500 | loss: 108.149
iter:3600 | loss: 97.943
iter:3700 | loss: 128.098
iter:3800 | loss: 198.458
iter:3900 | loss: 151.830
| end of epoch  23 | time: 858.80s | train_loss 147.2381 | valid rse 0.0509 | valid rae 0.0371 | valid corr  0.9390
iter:  0 | loss: 126.625
iter:100 | loss: 266.381
iter:200 | loss: 120.564
iter:300 | loss: 128.365
iter:400 | loss: 163.701
iter:500 | loss: 241.618
iter:600 | loss: 103.523
iter:700 | loss: 156.010
iter:800 | loss: 101.993
iter:900 | loss: 107.902
iter:1000 | loss: 145.671
iter:1100 | loss: 128.569
iter:1200 | loss: 133.139
iter:1300 | loss: 198.339
iter:1400 | loss: 206.041
iter:1500 | loss: 137.206
iter:1600 | loss: 136.470
iter:1700 | loss: 94.191
iter:1800 | loss: 157.022
iter:1900 | loss: 105.167
iter:2000 | loss: 150.888
iter:2100 | loss: 191.537
iter:2200 | loss: 117.866
iter:2300 | loss: 165.706
iter:2400 | loss: 99.368
iter:2500 | loss: 144.237
iter:2600 | loss: 133.170
iter:2700 | loss: 155.323
iter:2800 | loss: 139.965
iter:2900 | loss: 151.500
iter:3000 | loss: 176.488
iter:3100 | loss: 206.227
iter:3200 | loss: 228.872
iter:3300 | loss: 174.863
iter:3400 | loss: 130.922
iter:3500 | loss: 232.827
iter:3600 | loss: 105.098
iter:3700 | loss: 117.019
iter:3800 | loss: 106.284
iter:3900 | loss: 248.184
| end of epoch  24 | time: 859.08s | train_loss 146.6037 | valid rse 0.0518 | valid rae 0.0370 | valid corr  0.9401
iter:  0 | loss: 130.779
iter:100 | loss: 217.852
iter:200 | loss: 91.327
iter:300 | loss: 106.092
iter:400 | loss: 218.244
iter:500 | loss: 145.049
iter:600 | loss: 108.508
iter:700 | loss: 226.515
iter:800 | loss: 140.920
iter:900 | loss: 246.151
iter:1000 | loss: 108.248
iter:1100 | loss: 137.358
iter:1200 | loss: 90.748
iter:1300 | loss: 129.059
iter:1400 | loss: 123.087
iter:1500 | loss: 128.297
iter:1600 | loss: 129.625
iter:1700 | loss: 202.629
iter:1800 | loss: 121.123
iter:1900 | loss: 148.953
iter:2000 | loss: 118.890
iter:2100 | loss: 153.941
iter:2200 | loss: 118.179
iter:2300 | loss: 162.351
iter:2400 | loss: 104.321
iter:2500 | loss: 201.583
iter:2600 | loss: 163.431
iter:2700 | loss: 173.466
iter:2800 | loss: 126.992
iter:2900 | loss: 101.062
iter:3000 | loss: 134.898
iter:3100 | loss: 130.331
iter:3200 | loss: 111.812
iter:3300 | loss: 185.721
iter:3400 | loss: 116.329
iter:3500 | loss: 152.690
iter:3600 | loss: 192.184
iter:3700 | loss: 179.695
iter:3800 | loss: 95.316
iter:3900 | loss: 172.824
| end of epoch  25 | time: 860.24s | train_loss 146.2515 | valid rse 0.0517 | valid rae 0.0377 | valid corr  0.9393
test rse 0.0776 | test rae 0.0452 | test corr 0.9464
iter:  0 | loss: 189.954
iter:100 | loss: 99.578
iter:200 | loss: 201.478
iter:300 | loss: 147.217
iter:400 | loss: 191.981
iter:500 | loss: 107.090
iter:600 | loss: 200.359
iter:700 | loss: 134.019
iter:800 | loss: 137.046
iter:900 | loss: 159.932
iter:1000 | loss: 167.363
iter:1100 | loss: 142.099
iter:1200 | loss: 171.545
iter:1300 | loss: 101.124
iter:1400 | loss: 125.057
iter:1500 | loss: 183.366
iter:1600 | loss: 134.822
iter:1700 | loss: 137.531
iter:1800 | loss: 233.677
iter:1900 | loss: 125.111
iter:2000 | loss: 146.202
iter:2100 | loss: 174.786
iter:2200 | loss: 216.635
iter:2300 | loss: 152.834
iter:2400 | loss: 206.032
iter:2500 | loss: 94.029
iter:2600 | loss: 138.387
iter:2700 | loss: 139.012
iter:2800 | loss: 102.742
iter:2900 | loss: 172.362
iter:3000 | loss: 213.502
iter:3100 | loss: 178.781
iter:3200 | loss: 136.993
iter:3300 | loss: 165.128
iter:3400 | loss: 111.000
iter:3500 | loss: 131.710
iter:3600 | loss: 114.560
iter:3700 | loss: 115.504
iter:3800 | loss: 124.413
iter:3900 | loss: 140.471
| end of epoch  26 | time: 857.86s | train_loss 145.1584 | valid rse 0.0500 | valid rae 0.0349 | valid corr  0.9387
iter:  0 | loss: 182.597
iter:100 | loss: 147.054
iter:200 | loss: 121.247
iter:300 | loss: 228.276
iter:400 | loss: 112.270
iter:500 | loss: 147.701
iter:600 | loss: 118.538
iter:700 | loss: 145.907
iter:800 | loss: 169.595
iter:900 | loss: 96.736
iter:1000 | loss: 141.083
iter:1100 | loss: 118.307
iter:1200 | loss: 94.525
iter:1300 | loss: 126.367
iter:1400 | loss: 89.037
iter:1500 | loss: 116.366
iter:1600 | loss: 196.677
iter:1700 | loss: 123.896
iter:1800 | loss: 116.611
iter:1900 | loss: 125.225
iter:2000 | loss: 107.494
iter:2100 | loss: 140.828
iter:2200 | loss: 171.178
iter:2300 | loss: 155.982
iter:2400 | loss: 173.958
iter:2500 | loss: 151.590
iter:2600 | loss: 246.221
iter:2700 | loss: 99.822
iter:2800 | loss: 150.622
iter:2900 | loss: 174.944
iter:3000 | loss: 136.124
iter:3100 | loss: 86.959
iter:3200 | loss: 104.780
iter:3300 | loss: 119.952
iter:3400 | loss: 121.275
iter:3500 | loss: 110.047
iter:3600 | loss: 128.612
iter:3700 | loss: 118.142
iter:3800 | loss: 162.986
iter:3900 | loss: 147.387
| end of epoch  27 | time: 858.37s | train_loss 145.3046 | valid rse 0.0496 | valid rae 0.0347 | valid corr  0.9395
iter:  0 | loss: 117.255
iter:100 | loss: 137.985
iter:200 | loss: 116.334
iter:300 | loss: 95.653
iter:400 | loss: 113.187
iter:500 | loss: 140.877
iter:600 | loss: 133.416
iter:700 | loss: 132.266
iter:800 | loss: 140.183
iter:900 | loss: 230.156
iter:1000 | loss: 136.174
iter:1100 | loss: 169.864
iter:1200 | loss: 145.966
iter:1300 | loss: 120.726
iter:1400 | loss: 210.545
iter:1500 | loss: 116.063
iter:1600 | loss: 148.225
iter:1700 | loss: 140.072
iter:1800 | loss: 147.450
iter:1900 | loss: 113.142
iter:2000 | loss: 170.650
iter:2100 | loss: 131.549
iter:2200 | loss: 126.838
iter:2300 | loss: 152.477
iter:2400 | loss: 218.120
iter:2500 | loss: 144.012
iter:2600 | loss: 234.760
iter:2700 | loss: 126.206
iter:2800 | loss: 103.924
iter:2900 | loss: 140.813
iter:3000 | loss: 90.542
iter:3100 | loss: 150.181
iter:3200 | loss: 111.542
iter:3300 | loss: 128.256
iter:3400 | loss: 135.772
iter:3500 | loss: 142.044
iter:3600 | loss: 165.538
iter:3700 | loss: 117.787
iter:3800 | loss: 119.961
iter:3900 | loss: 114.742
| end of epoch  28 | time: 859.29s | train_loss 144.3736 | valid rse 0.0500 | valid rae 0.0350 | valid corr  0.9390
iter:  0 | loss: 115.811
iter:100 | loss: 125.884
iter:200 | loss: 89.744
iter:300 | loss: 158.191
iter:400 | loss: 140.308
iter:500 | loss: 151.541
iter:600 | loss: 170.319
iter:700 | loss: 115.839
iter:800 | loss: 244.253
iter:900 | loss: 98.741
iter:1000 | loss: 155.105
iter:1100 | loss: 151.413
iter:1200 | loss: 112.311
iter:1300 | loss: 135.864
iter:1400 | loss: 215.884
iter:1500 | loss: 146.757
iter:1600 | loss: 127.674
iter:1700 | loss: 186.073
iter:1800 | loss: 251.798
iter:1900 | loss: 152.069
iter:2000 | loss: 119.792
iter:2100 | loss: 135.023
iter:2200 | loss: 115.299
iter:2300 | loss: 123.270
iter:2400 | loss: 255.752
iter:2500 | loss: 155.980
iter:2600 | loss: 113.019
iter:2700 | loss: 190.893
iter:2800 | loss: 163.238
iter:2900 | loss: 156.963
iter:3000 | loss: 105.001
iter:3100 | loss: 151.392
iter:3200 | loss: 187.725
iter:3300 | loss: 158.515
iter:3400 | loss: 171.310
iter:3500 | loss: 132.892
iter:3600 | loss: 157.072
iter:3700 | loss: 131.810
iter:3800 | loss: 96.087
iter:3900 | loss: 136.795
| end of epoch  29 | time: 858.42s | train_loss 143.9136 | valid rse 0.0513 | valid rae 0.0364 | valid corr  0.9406
iter:  0 | loss: 190.198
iter:100 | loss: 112.953
iter:200 | loss: 137.064
iter:300 | loss: 104.113
iter:400 | loss: 92.006
iter:500 | loss: 199.191
iter:600 | loss: 122.577
iter:700 | loss: 162.638
iter:800 | loss: 91.907
iter:900 | loss: 137.865
iter:1000 | loss: 113.415
iter:1100 | loss: 156.148
iter:1200 | loss: 227.884
iter:1300 | loss: 105.443
iter:1400 | loss: 171.743
iter:1500 | loss: 139.110
iter:1600 | loss: 112.746
iter:1700 | loss: 119.382
iter:1800 | loss: 92.540
iter:1900 | loss: 123.876
iter:2000 | loss: 154.016
iter:2100 | loss: 126.549
iter:2200 | loss: 179.112
iter:2300 | loss: 89.752
iter:2400 | loss: 158.705
iter:2500 | loss: 142.575
iter:2600 | loss: 213.206
iter:2700 | loss: 119.253
iter:2800 | loss: 158.975
iter:2900 | loss: 139.265
iter:3000 | loss: 166.539
iter:3100 | loss: 197.482
iter:3200 | loss: 166.581
iter:3300 | loss: 105.914
iter:3400 | loss: 187.649
iter:3500 | loss: 157.953
iter:3600 | loss: 188.216
iter:3700 | loss: 95.253
iter:3800 | loss: 164.259
iter:3900 | loss: 114.865
| end of epoch  30 | time: 858.30s | train_loss 143.9200 | valid rse 0.0497 | valid rae 0.0348 | valid corr  0.9403
test rse 0.0760 | test rae 0.0420 | test corr 0.9468
final test rse 0.0751 | test rae 0.0414 | test corr 0.9465